{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QdXZwzubDwxG"
   },
   "source": [
    "# 2018 NUS-MIT Datathon Tutorial: Machine Learning on CBIS-DDSM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4cU4W9fc2X9i"
   },
   "source": [
    "## Goal\n",
    "\n",
    "In this colab, we are going to train a simple [convolutional neural network (CNN)](https://en.wikipedia.org/wiki/Convolutional_neural_network) with Tensorflow, which can be used to classify the mammographic images based on [breast density](https://www.cancercenter.com/discussions/blog/breast-density-becoming-an-important-predictor-of-breast-cancer-risk/).\n",
    "\n",
    "The network we are going to build is adapted from the [official tensorflow tutorial](https://www.tensorflow.org/tutorials/layers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BZ0dsLgReXpy"
   },
   "source": [
    "## CBIS-DDSM\n",
    "\n",
    "The dataset we are going to work with is [CBIS-DDSM](https://wiki.cancerimagingarchive.net/display/Public/CBIS-DDSM). Quote from their website:\n",
    "\n",
    "> \"This CBIS-DDSM (Curated Breast Imaging Subset of DDSM) is an updated and standardized version of the Digital Database for Screening Mammography (DDSM).\"\n",
    "\n",
    "CBIS-DDSM differs from the [original DDSM dataset](http://marathon.csee.usf.edu/Mammography/Database.html) in that it converted images to [DICOM](https://en.wikipedia.org/wiki/DICOM) format, which is easier to work with.\n",
    "\n",
    "Note that although this tutorial focuses on the CBIS-DDSM dataset, most of it can be easily applied to [The International Skin Imaging Collaboration (ISIC)](https://isic-archive.com/) dataset as well. More details will be provided in the Datasets section below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XTq9skVd3E9i"
   },
   "source": [
    "## Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DYPU5G2c2FKy"
   },
   "source": [
    "To be able to run the code cells in this tutorial, you need to create a copy of this Colab notebook by clicking \"File\" > \"Save a copy in Drive...\" menu.\n",
    "\n",
    "You can share your copy with your teammates by clicking on the \"SHARE\" button on the top-right corner of your Colab notebook copy. Everyone with \"Edit\" permission is able to modify the notebook at the same time, so it is a great way for team collaboration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WCc22o_Yhbyh"
   },
   "source": [
    "First Let's import modules needed to complete the tutorial. You can run the following cell by clicking on the triangle button when you hover over the [ ] space on the top-left corner of the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "uzFlTi_cUB0b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import SimpleITK as sitk\n",
    "import cv2\n",
    "\n",
    "\n",
    "from io import BytesIO\n",
    "from matplotlib import pyplot\n",
    "# The next import is used to print out pretty pandas dataframes\n",
    "from IPython.display import display, HTML\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YyrN2mlg40_y"
   },
   "source": [
    "You can verify that GPU is working with the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "o8ndJcsW6Jv1"
   },
   "outputs": [],
   "source": [
    "# Should output something like '/device:GPU:0'.\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ARL2DlauySyB"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "We have already extracted the images from the DICOM files to [separate folders](http://storage.cloud.google.com/datathon-cbis-ddsm-colab) on GCS, and some preprocessing were also done with the raw images (If you need custom preprocessing, please consult our [tutorial on image preprocessing](http://colab.research.google.com/github/GoogleCloudPlatform/healthcare/blob/master/datathon/nusdatathon18/tutorials/image_preprocessing.ipynb)).\n",
    "\n",
    "The folders ending with `_demo` contain subsets of training and test images. Specifically, the demo training dataset has 100 images, with 25 images for each [breast density category](https://breast-cancer.ca/densitbi-rads/) (1 - 4). There are 20 images in the test dataset which were selected randomly. All the images were first padded to 5251x7111 (largest width and height among the selected images) and then resized to 95x128 to fit in memory and save training time. Both training and test images are [\"Cranial-Caudal\"](https://breast-cancer.ca/mammopics/) only.\n",
    "\n",
    "[ISIC dataset](http://storage.cloud.google.com/isic-images) is organized in a slightly different way, the images are in JPEG format and each image comes with a JSON file containing metadata information. In order to make this tutorial work for ISIC, you will need to first pad and resize the images (we provide a script to do that [here](https://github.com/GoogleCloudPlatform/healthcare/tree/master/datathon/nusdatathon18/scripts)), and extract the labels from the JSON files based on your interests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZvhHlBs80TtW"
   },
   "source": [
    "## Training\n",
    "\n",
    "Before coding on our neurual network,  let's create a few helper methods to make loading data from Google Cloud Storage (GCS) easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vJDuv_a50s1L"
   },
   "outputs": [],
   "source": [
    "def load_img_label(train = True):\n",
    "    if train:\n",
    "        df = pd.read_csv(os.getcwd() + \"/../CBIS-DDSM-classic/calc_case_description_train_set.csv\")\n",
    "    else:\n",
    "        df = pd.read_csv(os.getcwd() + \"/../CBIS-DDSM-classic/calc_case_description_test_set.csv\")\n",
    "        \n",
    "    df = df[df[\"breast density\"] != 0]\n",
    "    img_dir =  os.getcwd() + \"/../CBIS-DDSM-classic/\" + df[\"image file path\"]\n",
    "    label = df[\"breast density\"]\n",
    "    \n",
    "    return img_dir.values, label.values\n",
    "\n",
    "\n",
    "def load_images(train = True):\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    img_dirs, _labels = load_img_label(train) \n",
    "    idx = np.arange(0 , int(len(img_dirs)/15))\n",
    "    np.random.shuffle(idx)\n",
    "    img_dirs = [img_dirs[i] for i in idx]\n",
    "    _labels = [_labels[i] for i in idx]\n",
    "    blob = zip(img_dirs, _labels)\n",
    "       \n",
    "    for img_dir, _label in blob:\n",
    "        \n",
    "        img = sitk.ReadImage(img_dir)\n",
    "        img = sitk.GetArrayFromImage(img)\n",
    "        img = np.array(img, dtype= np.float32)\n",
    "        img = np.squeeze(img)/10000\n",
    "        img = cv2.resize(img, dsize = (95,128))\n",
    "        images.append(img)\n",
    "        labels.append(_label-1)\n",
    "        \n",
    "    return np.array(images), np.array(labels, dtype=np.int32)\n",
    "\n",
    "def load_train_images():\n",
    "    return load_images(train = True)\n",
    "\n",
    "def load_test_images():\n",
    "    return load_images(train = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_EbunSiVv-fR"
   },
   "source": [
    "Let's create a model function, which will be passed to an estimator that we will create later. The model has an architecture of 6 layers:\n",
    "\n",
    "1.   *Convolutional Layer*: Applies 32 5x5 filters, with ReLU activation function\n",
    "2.   *Pooling Layer*: Performs max pooling with a 2x2 filter and stride of 2\n",
    "3.   *Convolutional Layer*: Applies 64 5x5 filters, with ReLU activation function\n",
    "4.   *Pooling Layer*: Same setup as #2\n",
    "5.   *Dense Layer*: 1,024 neurons,  with dropout regulartization rate of 0.25\n",
    "6.   *Logits Layer*: 4 neurons, one for each breast density category, i.e. [0, 4)\n",
    "\n",
    "Note that you can change the parameters on the right (or inline) to tune the neurual network. It is **highly recommended** to check out the original [tensorflow tutorial](https://www.tensorflow.org/tutorials/layers) to get a deeper understanding of the network we are building here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YT35BUUWtjzT"
   },
   "outputs": [],
   "source": [
    "KERNEL_SIZE = 5 #@param\n",
    "DROPOUT_RATE = 0.25 #@param\n",
    "\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "  \"\"\"Model function for CNN.\"\"\"\n",
    "\n",
    "  # Input Layer.\n",
    "  # Reshape to 4-D tensor: [batch_size, height, width, channels]\n",
    "  # DDSM images are grayscale, which have 1 channel.\n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 95, 128, 1])\n",
    "\n",
    "  # Convolutional Layer #1.\n",
    "  # Input Tensor Shape: [batch_size, 95, 128, 1]\n",
    "  # Output Tensor Shape: [batch_size, 95, 128, 32]\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=KERNEL_SIZE,\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #1.\n",
    "  # Input Tensor Shape: [batch_size, 95, 128, 1]\n",
    "  # Output Tensor Shape: [batch_size, 47, 64, 32]\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #2.\n",
    "  # Input Tensor Shape: [batch_size, 47, 64, 32]\n",
    "  # Output Tensor Shape: [batch_size, 47, 64, 64]\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=KERNEL_SIZE,\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #2.\n",
    "  # Input Tensor Shape: [batch_size, 47, 64, 32]\n",
    "  # Output Tensor Shape: [batch_size, 23, 32, 64]\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Flatten tensor into a batch of vectors\n",
    "  # Input Tensor Shape: [batch_size, 23, 32, 64]\n",
    "  # Output Tensor Shape: [batch_size, 23 * 32 * 64]\n",
    "  pool2_flat = tf.reshape(pool2, [-1, 23 * 32 * 64])\n",
    "\n",
    "  # Dense Layer.\n",
    "  # Input Tensor Shape: [batch_size, 25 * 17 * 64]\n",
    "  # Output Tensor Shape: [batch_size, 1024]\n",
    "  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "  # Dropout operation.\n",
    "  # 0.75 probability that element will be kept.\n",
    "  dropout = tf.layers.dropout(inputs=dense, rate=DROPOUT_RATE,\n",
    "                              training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "  # Logits Layer.\n",
    "  # Input Tensor Shape: [batch_size, 1024]\n",
    "  # Output Tensor Shape: [batch_size, 4]\n",
    "  logits = tf.layers.dense(inputs=dropout, units=4)\n",
    "\n",
    "  predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Loss Calculation.\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode).\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o10H3NS0z4AZ"
   },
   "source": [
    "Now that we have a model function, next step is feeding it to an estimator for training. Here are are creating a main function as required by tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sz0NHd3vUm5p"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20 #@param\n",
    "STEPS = 10000 #@param\n",
    "\n",
    "def main(_):\n",
    "  # Load training and test data.\n",
    "  train_data, train_labels = load_train_images()\n",
    "  eval_data, eval_labels = load_test_images()\n",
    "\n",
    "  # Create the Estimator.\n",
    "  ddsm_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn)\n",
    "\n",
    "  # Set up logging for predictions.\n",
    "  # Log the values in the \"Softmax\" tensor with label \"probabilities\".\n",
    "  tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "  logging_hook = tf.train.LoggingTensorHook(\n",
    "      tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "  # Train the model.\n",
    "  train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": train_data},\n",
    "      y=train_labels,\n",
    "      batch_size=BATCH_SIZE,\n",
    "      num_epochs=None,\n",
    "      shuffle=True)\n",
    "  ddsm_classifier.train(\n",
    "      input_fn=train_input_fn,\n",
    "      steps=STEPS,\n",
    "      hooks=[logging_hook])\n",
    "\n",
    "  # Evaluate the model and print results.\n",
    "  eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": eval_data},\n",
    "      y=eval_labels,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "  eval_results = ddsm_classifier.evaluate(input_fn=eval_input_fn)\n",
    "  print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B4IT85Hg0lTY"
   },
   "source": [
    "Finally, here comes the exciting moment. We are going to train and evaluate the model we just built! Run the following code cell and pay attention to the accuracy printed at the end of logs.\n",
    "\n",
    "Note if this is **not** the first time you run the following cell, to avoid weird errors like \"NaN loss during training\", please run the following command to remove the temporary files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5ixTe8T6pU10"
   },
   "outputs": [],
   "source": [
    "# Set logging level.\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# Start training, this will call the main method defined above behind the scene.\n",
    "# The whole training process will take ~5 mins.\n",
    "tf.app.run()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "2018 NUS-MIT Datathon Tutorial Machine Learning on CBIS-DDSM",
   "provenance": [
    {
     "file_id": "/piper/depot/google3/third_party/cloud/healthcare/datathon/nusdatathon18/tutorials/ddsm_ml_tutorial.ipynb?workspaceId=lastomato:lastomato0-lastomato-cloud-machine_learning_colab-git5::citc",
     "timestamp": 1528410196234
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
